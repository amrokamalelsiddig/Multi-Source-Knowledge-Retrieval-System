{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Source Information Retrieval Project\n",
    "This notebook demonstrates how to build a multi-source information retrieval system that processes documents from various sources and provides relevant answers to user queries. We'll be leveraging different document sources like Wikipedia and Arxiv, as well as vector-based similarity searches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setting Up the Environment\n",
    "We'll start by loading the necessary libraries and modules for document retrieval and processing. Additionally, we'll load environment variables for API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun, ArxivQueryRun\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain import hub\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Setting Up Retrieval Tools for Wikipedia and Arxiv\n",
    "We will now set up tools to retrieve information from Wikipedia and Arxiv. These tools help us fetch specific document segments from these sources based on user queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wikipedia tool\n",
    "wiki_api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=wiki_api_wrapper)\n",
    "\n",
    "# Arxiv tool\n",
    "arxiv_api_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
    "arxiv_tool = ArxivQueryRun(api_wrapper=arxiv_api_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Loading Documents from a Website and Setting Up a Searchable Index\n",
    "We will load documents from a website and split them into smaller sections for processing. Using vector-based similarity searches, we will then create an index that allows us to retrieve relevant documents based on a user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Load documents from the web // i have used langsmith docs but you can you use any other web page \n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split documents into chunks for better processing\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "documents = splitter.split_documents(docs)\n",
    "\n",
    "# Create a vector-based searchable index using FAISS\n",
    "vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Setting Up Tools for LangSmith Search\n",
    "We'll now configure a custom search tool that will enable us to retrieve documents related to LangSmith, an important topic in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom search tool for LangSmith\n",
    "retriever_tool = create_retriever_tool(retriever, \"langsmith_search\", \"Search for information about LangSmith\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Setting Up the Main System and Agent\n",
    "We will combine all the tools into an agent that can retrieve and process information. The agent is capable of querying multiple sources and delivering relevant results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all tools into an agent\n",
    "tools = [wiki_tool, retriever_tool, arxiv_tool]\n",
    "\n",
    "# Load a pre-built prompt from the hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "# Create the agent\n",
    "agent = create_openai_tools_agent(LLM, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Querying the System\n",
    "We can now use the agent to query the system. It will retrieve relevant information based on the user's input, drawing from the various sources we configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Execute queries with the agent\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "response = agent_executor.invoke({\"input\": \"Tell me about LangSmith\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Additional Queries\n",
    "We can now ask additional questions to the system, allowing it to retrieve and display information from various sources based on the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the system with other topics\n",
    "response_2 = agent_executor.invoke({\"input\": \"Tell me about the latest research on data science.\"})\n",
    "response_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This project demonstrates how we can build a powerful information retrieval system that processes documents from multiple sources and provides relevant responses to user queries. By utilizing document processing techniques and vector-based similarity search, we can ensure accurate and context-aware results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
